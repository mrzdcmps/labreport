---
title: "Discussion"
format: 
  html:
    page-layout: full
toc: true
page-navigation: true
---

::: callout-note
This section will be updated with each new release of the report.

Current version: *Studies 2016 - 2025* (v2)
:::

```{r setup, include=FALSE}
st <- readRDS("data/overview2025-07-12.rds")
load("data/study_objects.RData")

# Number of Studies
study_objects <- ls(pattern = "^study")
numbers <- as.numeric(gsub("study([0-9]+).*", "\\1", study_objects))
max_number <- max(numbers)

# Number of individual participants
exclude_studies <- c(
  "Monks T2 Exp",
  "Monks T2 Con",
  "Psyscanner Style 2 Exp",
  "Psyscanner Style 2 Con",
  "Psyscanner Style 3 Exp",
  "Psyscanner Style 3 Con",
  "Priming 1 Con",
  "Priming 2 Con",
  "Priming 3 Con",
  "Priming 4 Con",
  "Smokers Priming Con",
  "Epsi Correlation Condition B",
  "Schrödingers Cat Con"
)

n_participants <- sum(st[!(st$Study %in% exclude_studies), ]$N, na.rm = TRUE)


#Frequentist m-a with metafor 
library(metafor)

# Specify parameters of Exp Studies
exp <- subset(st, Experimental == TRUE)
yi=exp$ES
vi=exp$Var
studies=exp$Study

yi[which(studies == "Smokers 1 Exp")] <- -yi[which(studies == "Smokers 1 Exp")]
yi[which(studies == "Smokers 2 Exp")] <- -yi[which(studies == "Smokers 2 Exp")]
yi[which(studies == "Smokers 3")] <- -yi[which(studies == "Smokers 3")]
yi[which(studies == "Baseline 1 Lucky")] <- -yi[which(studies == "Baseline 1 Lucky")]
yi[which(studies == "Baseline 2")] <- -yi[which(studies == "Baseline 2")]

res.e <- rma(
  yi,
  vi, 
  method="REML",
  knha=TRUE,
  slab=paste(studies)
  )

# Control studies
con <- subset(st, Experimental == FALSE)
yi=con$ES
vi=con$Var
studies=con$Study

yi[which(studies == "Smokers 2 Con")] <- -yi[which(studies == "Smokers 2 Con")]

res.c <- rma(
  yi,
  vi, 
  method="REML",
  knha=TRUE,
  slab=paste(studies)
  )

# CoE Meta-Analysis
library(metap)
coe <- readRDS("data/coe_2025-07-14.rds")

# Select studies / conditions
exp <- subset(coe, coe$Experimental == TRUE)

istwo <- ifelse(exp$Direction == "different", TRUE, FALSE) # two-tailed test
df <- exp$N-1 # degrees of freedom

e.maxbf <- invchisq(two2one(exp$`MaxBF p`, istwo), k=df)
e.bfenergy <- invchisq(two2one(exp$`Energy p`, istwo), k=df)
e.fft <- invchisq(two2one(exp$`FFT p`, istwo), k=df)

con <- subset(coe, coe$Experimental == FALSE)

istwo <- ifelse(con$Direction == "different", TRUE, FALSE) # two-tailed test
df <- con$N-1 # degrees of freedom

c.maxbf <- invchisq(two2one(con$`MaxBF p`, istwo), k=df)
c.bfenergy <- invchisq(two2one(con$`Energy p`, istwo), k=df)
c.fft <- invchisq(two2one(con$`FFT p`, istwo), k=df)

options(scipen = 999)
```

## Summary of Results

The meta-analytic assessment of all micro-PK experiments conducted at the LMU Micro-PK lab currently encompasses `{r} print(max_number)` studies with a total of `{r} nrow(subset(st, st$Experimental == TRUE))` experimental conditions and `{r} nrow(subset(st, st$Experimental == FALSE))` control conditions, including data from `{r} n_participants` individual participants and reveals several key insights. Although individual studies included in this report often tested specific hypotheses, the meta-analysis focused on a general micro-PK effect to ensure comparability. Descriptions of the hypotheses for each study can be found in the respective [experiments](experiments.html) section.

The overall effect size for micro-PK was found to be  marginally significant (`{r} round(res.e$b,3)`, *p* = `{r} round(res.e$pval,3)`) across experimental conditions, with moderate heterogeneity (`{r} round(res.e$I2,2)`%). Control conditions showed no significant effect (`{r} round(res.c$b,3)`, *p* = `{r} round(res.c$pval,3)`) with low heterogeneity (`{r} round(res.c$I2,2)`%). These results suggest that while the experimental manipulations may produce a weak effect, it is not robust enough to reach conventional significance levels. The moderate heterogeneity in experimental conditions compared to the low heterogeneity in control conditions indicates that variability is more likely due to differences in interventions rather than methodological factors.

## Change of Evidence Measures

Since Psi-effects may be influenced by the accumulation of evidence over time, new measures have been devised to analyze how this [evidence changes](coe-measures.html). By comparing these results to simulations, empirical p-values can be calculated. A meta-analytic assessment of these change-of-evidence measures was conducted using the inverse chi-square `invchisq`-function to combine p-values across studies. Three characteristics were analyzed: Maximum Bayes Factor (BF), BF Energy, and the amplitude sum of the BF curve’s Fast Fourier Transform (FFT).

For all experimental conditions, the combined chi-square statistics were calculated with `{r} e.maxbf$df` degrees of freedom, yielding the following results: `{r} round(e.maxbf$chisq,2)` for the Maximum BF (*p* = `{r} round(e.maxbf$p,3)`), `{r} round(e.bfenergy$chisq,2)` for the BF Energy (*p* = `{r} round(e.bfenergy$p,3)`) and `{r} round(e.fft$chisq,2)` for the FFT amplitude sum (*p* = `{r} round(e.fft$p,3)`).

The analysis of change of evidence measures revealed mixed results for experimental conditions. While the Maximum BF showed no significant deviation from chance expectations (*p* = `{r} round(e.maxbf$p,3)`), both BF Energy (*p* = `{r} round(e.bfenergy$p,3)`) and FFT amplitude sum (*p* = `{r} round(e.fft$p,3)`) demonstrated statistically significant results. This pattern suggests that while the peak evidence accumulation may not differ substantially from simulated data, the overall energy and frequency characteristics of evidence changes show systematic deviations from random variation. The assignment of $p_{MaxBF} = 1$ to studies in the direction of H0 (MaxBF = 1) might be responsible for the difference and suggests that the MaxBF criterion could be limited.

Nonetheless, the significant findings for BF Energy and FFT amplitude sum indicate the presence of a subtle but detectable pattern in how evidence accumulates over time in experimental conditions, potentially reflecting a volatile micro-PK effect that manifests not as consistent directional changes but as systematic alterations in the dynamics of evidence accumulation. The tests are robust to using methods that do or do not account for varying sample sizes, thus addressing potential issues of overweighting studies that show a noticeable BF early on and whose data collection is extended.

In contrast, none of the three characteristics demonstrated statistically significant results for the control conditions. However, these significant results for two of the three measures in experimental conditions do not necessarily translate into a substantial overall effect, as only a marginally significant effect was found in the aggregate meta-analysis of micro-PK interventions. They do, however, indicate that the observed changes in evidence accumulation patterns are not likely due to random variation alone, suggesting that experimental manipulations may influence the temporal dynamics of evidence accumulation even when they do not produce detectable overall effects.

## Addressing Publication Bias

A potential concern in meta-analyses is publication bias, where significant results are more likely to be published compared to non-significant findings. In our case, the comprehensive inclusion of both published and unpublished studies from our research group effectively mitigates this concern. By incorporating all relevant studies, our analysis is less susceptible to selective reporting, enhancing the reliability of our findings.

## Implications of Findings

The significant change of evidence measures for BF Energy and FFT amplitude sum in experimental conditions suggest dynamic factors influencing evidence accumulation patterns. This goes hand in hand with theories about decline effects in (parapsychologcial) science. E.g., the Model of Pragmatic Information suggests that novel, autonomous effects may decrease in detectability over time. It may explain the observed volatility and highlights the potential of change of evidence measures for understanding temporal dynamics in micro-PK effects.

Weak and volatile effects are often observed in parapsychological research, exemplified by failed direct replications, a phenomenon known as the decline effect. This pattern is not unique to Psi research but has been documented in other scientific areas as well. The change of evidence measures presented here might offer a fruitful approach to identify decline patterns within individual studies and differentiate between false positives combined with regression to the mean versus genuine effect-plus-decline patterns.

The marginally significant overall effect size (*p* = `{r} round(res.e$pval,3)`) suggests that micro-PK interventions may produce a weak but detectable effect, though not at conventional significance levels. This finding, combined with the significant change of evidence measures, indicates that while micro-PK effects may be present, they are subtle and may manifest primarily through alterations in evidence accumulation dynamics rather than consistent directional effects. Future research should focus on refining experimental designs, replicating studies, and exploring the underlying mechanisms of micro-PK effects to establish more robust evidence.

## Conclusion

While our meta-analysis demonstrated only a marginally significant effect of micro-PK interventions (p = 0.072), the significant change of evidence measures for BF Energy and FFT amplitude sum in experimental conditions indicate that the phenomena observed are not purely due to chance. These findings suggest that micro-PK effects, while subtle, may influence the temporal dynamics of evidence accumulation in ways that traditional effect size measures might not fully capture.

Future research should focus on refining experimental designs, conducting replication studies, and maintaining transparent reporting practices to further explore and validate micro-PK effects. Particular attention should be given to understanding the mechanisms underlying the observed changes in evidence accumulation patterns. Addressing these aspects will help in understanding the underlying mechanisms and improving the robustness of evidence in this field.

We would like to additionally encourage the scientific community to follow this example of transparent reporting and data sharing to enhance the reproducibility and reliability of research findings in the field of parapsychology and related disciplines and to counteract publication bias and selective reporting practices.
