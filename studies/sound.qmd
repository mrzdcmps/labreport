---
title: "Sound Preference"
format: html
editor: visual
execute: 
  echo: false
  warning: false
---

```{r}
library(tidyverse)
library(knitr)
library(kableExtra)

load("../study_objects.RData")
st <- readRDS("../overview.rds")

ft <- st %>%
  filter(Study == "Sound preference") %>%
  mutate(
    across(where(is.numeric), ~ round(., 2)),
    `Hits (%)` = formattable::color_tile("coral2","cornflowerblue")(`Hits (%)`),
    p = cell_spec(p, bold = ifelse(p < 0.05, TRUE, FALSE)),
    Experimental = ifelse(Experimental, "✔", "✖"),
    Experimental = cell_spec(Experimental, color = ifelse(Experimental == "✔", "darkgreen", "red")),
    Labstudy = ifelse(Labstudy, "🏠", "🌍")
    )

kbl(ft, escape = F,
    col.names = c("Study",
                  "Effect expected",
                  "N",
                  "Trials",
                  "M",
                  "SD",
                  "Hits (%)",
                  "t",
                  "p",
                  "ES",
                  "Var",
                  "BF",
                  "Direction",
                  "Lab/Online"),
    align = "lccccccccccccc") %>%
  kable_classic("hover", fixed_thead = T)
```

## Hypothesis

Participants were asked to listen to 40 positive or negative audio stimuli. Before the stimulus presentation, a prerecorded relaxation exercise was played back. We hypothesized more positive audio stimuli ("hits") for all participants.

## Participants

```{r}
library(tidyverse)
library(knitr)

df <- study5_sound

# Data
total_participants <- nrow(df)
mean_age <- mean(df$A002_01, na.rm=T)
sd_age <- sd(df$A002_01, na.rm=T)
female_count <- sum(df$A001 == 1, na.rm=T)
male_count <- sum(df$A001 == 2, na.rm=T)

# Create the table
table_data <- data.frame(
  Characteristic = c("N", "Female", "Male", "Mean Age", "SD Age"),
  Count_Statistics = c(
    total_participants,
    female_count,
    male_count,
    paste0(round(mean_age, 2), " years"),
    paste0(round(sd_age, 2), " years")
    )
)

# Print the table using kable
kable(table_data, format = "html", col.names = c("Characteristic", "Count/Statistic")) %>%
  kableExtra::kable_styling(full_width = FALSE)

```

## Materials

Audio stimuli were taken from the International Affective Digitized Sounds [@bradley2007international] and consisted of 12 audio files with positive valence, e.g. laughter, bonfire, music (IDs: 110, 151, 220, 352, 377, 725, 726, 811, 815, 817, 820) and 12 audio files with negative valence, e.g. crying, bees, alarm (IDs: 115, 242, 255, 261, 277, 380, 420, 624, 709, 712, 719). Sounds had a duration of 6 seconds.

The relaxation exercise consisted of a 2-minute prerecorded audio file asking participants to focus on their breathing and become peaceful and relaxed.

## Procedure

Participants were tested online. After welcoming them a prerecorded relaxation audio file was read to them (2 mins). They were then presented with 40 audio stimuli, each one either randomly chosen from the positive stimulus set or from the negative stimulus set, depending on the qRNG outcome. They were then thanked and asked to fill out a questionnaire.

::: {.callout-tip title="Data" collapse="false"}
-   [Download Data](../data/sound/sound.csv)
:::

::: {.callout-note title="Resources" collapse="false"}
-   [Experimental Program](../data/sound/nor-sound.html)
-   [Relaxation Audio](../data/meditation/relaxation.mp3)
-   [Relaxation Audio English](../data/meditation/relaxation_e.mp3)
:::
